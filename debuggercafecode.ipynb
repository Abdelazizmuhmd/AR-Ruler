{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "debuggercafecode.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPAOTsg96Ab/fXyd50PVR5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdelazizmuhmd/AR-Ruler/blob/master/debuggercafecode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3D4Q6owXATO",
        "outputId": "3a3c850c-f3c5-4ded-b9c9-4df37208dae5"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_RoQqhEYq0J"
      },
      "source": [
        "import pandas as pd\r\n",
        "import joblib\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm\r\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFHF7O6RYtVn",
        "outputId": "ffc586b9-1eee-4671-947d-e17d40ef774b"
      },
      "source": [
        "all_paths = os.listdir('/content/gdrive/MyDrive/all/input/data')\r\n",
        "folder_paths = [x for x in all_paths if os.path.isdir('/content/gdrive/MyDrive/all/input/data/' + x)]\r\n",
        "print(f\"Folder paths: {folder_paths}\")\r\n",
        "print(f\"Number of folders: {len(folder_paths)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folder paths: ['normal', 'drowning']\n",
            "Number of folders: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Giu_GZZqqZ"
      },
      "source": [
        "# we will create the data for the following labels, \r\n",
        "# add more to list to use those for creating the data as well\r\n",
        "create_labels = ['normal', 'drowning']\r\n",
        "# create a DataFrame\r\n",
        "data = pd.DataFrame()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3OXmMikZxy5",
        "outputId": "7ac3bc0b-a1de-47ec-e6f9-f9af0be43c06"
      },
      "source": [
        "image_formats = ['jpg', 'JPG', 'PNG', 'png'] # we only want images that are in this format\r\n",
        "labels = []\r\n",
        "counter = 0\r\n",
        "for i, folder_path in tqdm(enumerate(folder_paths), total=len(folder_paths)):\r\n",
        "    if folder_path not in create_labels:\r\n",
        "        continue\r\n",
        "    image_paths = os.listdir('/content/gdrive/MyDrive/all/input/data/'+folder_path)\r\n",
        "    label = folder_path\r\n",
        "    # save image paths in the DataFrame\r\n",
        "    for image_path in image_paths:\r\n",
        "        if image_path.split('.')[-1] in image_formats:\r\n",
        "            data.loc[counter, 'image_path'] = f\"/content/gdrive/MyDrive/all/input/data/{folder_path}/{image_path}\"\r\n",
        "            labels.append(label)\r\n",
        "            counter += 1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.72it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAIUl7Q8aTch"
      },
      "source": [
        "labels = np.array(labels)\r\n",
        "# one-hot encode the labels\r\n",
        "lb = LabelBinarizer()\r\n",
        "labels = lb.fit_transform(labels)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm2CFhOoaXNA"
      },
      "source": [
        "if len(labels[0]) == 1:\r\n",
        "    for i in range(len(labels)):\r\n",
        "        index = labels[i]\r\n",
        "        data.loc[i, 'target'] = int(index)\r\n",
        "elif len(labels[0]) > 1:\r\n",
        "    for i in range(len(labels)):\r\n",
        "        index = np.argmax(labels[i])\r\n",
        "        data.loc[i, 'target'] = int(index)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfdSZz79aY4x",
        "outputId": "cec07273-44e8-4263-ae9a-17f2ad406cb4"
      },
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True)\r\n",
        "print(f\"Number of labels or classes: {len(lb.classes_)}\")\r\n",
        "print(f\"The first one hot encoded labels: {labels[0]}\")\r\n",
        "print(f\"Mapping the first one hot encoded label to its category: {lb.classes_[0]}\")\r\n",
        "print(f\"Total instances: {len(data)}\")\r\n",
        " \r\n",
        "# save as CSV file\r\n",
        "data.to_csv('/content/gdrive/MyDrive/all/input/data.csv', index=False)\r\n",
        " \r\n",
        "# pickle the binarized labels\r\n",
        "print('Saving the binarized labels as pickled file')\r\n",
        "joblib.dump(lb, '/content/gdrive/MyDrive/all/outputs/lb.pkl')\r\n",
        " \r\n",
        "print(data.head(5))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels or classes: 2\n",
            "The first one hot encoded labels: [1]\n",
            "Mapping the first one hot encoded label to its category: 0\n",
            "Total instances: 2000\n",
            "Saving the binarized labels as pickled file\n",
            "                                          image_path  target\n",
            "0  /content/gdrive/MyDrive/all/input/data/normal/...     1.0\n",
            "1  /content/gdrive/MyDrive/all/input/data/normal/...     1.0\n",
            "2  /content/gdrive/MyDrive/all/input/data/normal/...     1.0\n",
            "3  /content/gdrive/MyDrive/all/input/data/normal/...     1.0\n",
            "4  /content/gdrive/MyDrive/all/input/data/drownin...     0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHvoEizsa-Gz"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import joblib\r\n",
        "# load the binarized labels file\r\n",
        "lb = joblib.load('/content/gdrive/MyDrive/all/outputs/lb.pkl')\r\n",
        "class CustomCNN(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(CustomCNN, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, 16, 5)\r\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5)\r\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3)\r\n",
        "        self.conv4 = nn.Conv2d(64, 128, 5)\r\n",
        "        self.fc1 = nn.Linear(128, 256)\r\n",
        "        self.fc2 = nn.Linear(256, len(lb.classes_))\r\n",
        "        self.pool = nn.MaxPool2d(2, 2)\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.pool(F.relu(self.conv1(x)))\r\n",
        "        x = self.pool(F.relu(self.conv2(x)))\r\n",
        "        x = self.pool(F.relu(self.conv3(x)))\r\n",
        "        x = self.pool(F.relu(self.conv4(x)))\r\n",
        "        bs, _, _, _ = x.shape\r\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = self.fc2(x)\r\n",
        "        return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNUP82ixbGDZ"
      },
      "source": [
        "'''\r\n",
        "USAGE:\r\n",
        "python train.py --dataset ../input/data --model ../outputs/sports.pth --epochs 75\r\n",
        "'''\r\n",
        "import torch\r\n",
        "import argparse\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "import albumentations\r\n",
        "import torch.optim as optim\r\n",
        "import os\r\n",
        "#import cnn_models\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n",
        "import pandas as pd\r\n",
        "matplotlib.style.use('ggplot')\r\n",
        "from imutils import paths\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from torch.utils.data import DataLoader, Dataset\r\n",
        "from tqdm import tqdm\r\n",
        "from PIL import Image"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZprsf1ejKTP",
        "outputId": "9b572e20-b865-4c93-918b-f6dc325d5dac"
      },
      "source": [
        "lr = 1e-3\r\n",
        "batch_size = 32\r\n",
        "device = 'cuda:0'\r\n",
        "print(f\"Computation device: {device}\\n\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computation device: cuda:0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5wI5DNCjUKx",
        "outputId": "119d3e01-ba39-4d91-d57b-c2f15ca005cf"
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/all/input/data.csv')\r\n",
        "X = df.image_path.values # image paths\r\n",
        "y = df.target.values # targets\r\n",
        "(xtrain, xtest, ytrain, ytest) = train_test_split(X, y,\r\n",
        "    test_size=0.10, random_state=42)\r\n",
        "print(f\"Training instances: {len(xtrain)}\")\r\n",
        "print(f\"Validation instances: {len(xtest)}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training instances: 1800\n",
            "Validation instances: 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeil3zD7jaVg"
      },
      "source": [
        "# custom dataset\r\n",
        "class ImageDataset(Dataset):\r\n",
        "    def __init__(self, images, labels=None, tfms=None):\r\n",
        "        self.X = images\r\n",
        "        self.y = labels\r\n",
        "        # apply augmentations\r\n",
        "        if tfms == 0: # if validating\r\n",
        "            self.aug = albumentations.Compose([\r\n",
        "                albumentations.Resize(224, 224, always_apply=True),\r\n",
        "            ])\r\n",
        "        else: # if training\r\n",
        "            self.aug = albumentations.Compose([\r\n",
        "                albumentations.Resize(224, 224, always_apply=True),\r\n",
        "                albumentations.HorizontalFlip(p=0.5),\r\n",
        "                albumentations.ShiftScaleRotate(\r\n",
        "                    shift_limit=0.3,\r\n",
        "                    scale_limit=0.3,\r\n",
        "                    rotate_limit=15,\r\n",
        "                    p=0.5\r\n",
        "                ),\r\n",
        "            ])\r\n",
        "         \r\n",
        "    def __len__(self):\r\n",
        "        return (len(self.X))\r\n",
        "    \r\n",
        "    def __getitem__(self, i):\r\n",
        "        image = Image.open(self.X[i])\r\n",
        "        image = image.convert('RGB')\r\n",
        "        image = self.aug(image=np.array(image))['image']\r\n",
        "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\r\n",
        "        label = self.y[i]\r\n",
        "        return (torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-0qWkjojeKc"
      },
      "source": [
        "train_data = ImageDataset(xtrain, ytrain, tfms=1)\r\n",
        "test_data = ImageDataset(xtest, ytest, tfms=0)\r\n",
        "# dataloaders\r\n",
        "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\r\n",
        "testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}